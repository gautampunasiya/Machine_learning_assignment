{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d5f7e3-f02d-41e9-b722-adfc50652e5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862ae4e-a9eb-4022-a2f7-a6a464888607",
   "metadata": {},
   "source": [
    "Min-Max scaling, also known as normalization, is a data preprocessing technique used to rescale the values of a feature or variable to a specific range. It transforms the data so that it falls within a predetermined range, typically between 0 and 1.\n",
    "\n",
    "The formula for Min-Max scaling is as follows:\n",
    "\n",
    "scaled_value = (x - min_value) / (max_value - min_value)\n",
    "\n",
    "where 'x' is the original value, 'min_value' is the minimum value in the dataset, and 'max_value' is the maximum value in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718eeb16-fabc-4658-9c4c-40e310efb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price= [100000, 200000, 300000, 400000, 500000, 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45eef6f1-1e6f-4938-bdb8-d5bdcb88d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1995de7e-ca44-412c-886a-b9e4364f0304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Price, columns = ['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4375f40f-2a22-4f69-8263-dc741630917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price\n",
       "0  100000\n",
       "1  200000\n",
       "2  300000\n",
       "3  400000\n",
       "4  500000\n",
       "5  100000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7b60bee-01a6-4d8b-9c6c-864e4da2c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cdcf00c-92cb-4a85-8aae-247f4eee3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea7e7c78-5187-4f4d-8a3f-d0a761cdbebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price\n",
       "0   0.00\n",
       "1   0.25\n",
       "2   0.50\n",
       "3   0.75\n",
       "4   1.00\n",
       "5   0.00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(min_max.fit_transform(df[['price']]), columns=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988930ba-46a2-49a9-80eb-875a75a0ae5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c844587-0b32-4dd1-aa86-f3d0fad711a7",
   "metadata": {},
   "source": [
    "** The Unit Vector technique, also known as vector normalization or feature scaling, is a data preprocessing method that transforms the values of a feature or variable to have a unit norm, i.e., a length or magnitude of 1. It scales the feature vector to maintain the direction of the data while making its length uniform.\n",
    "\n",
    "\n",
    "\n",
    "The formula for unit vector scaling is as follows:\n",
    "\n",
    "\n",
    "scaled_value = x / ||x||\n",
    "\n",
    "\n",
    "where 'x' is the original value and ||x|| represents the Euclidean norm or magnitude of the vector.\n",
    "Unlike Min-Max scaling, which rescales the values to a specific range (e.g., 0 to 1), unit vector scaling focuses on maintaining the direction of the data while adjusting its magnitude. This technique is especially useful when the magnitude or length of the feature vectors is important in a particular analysis or when dealing with algorithms that are sensitive to the scale of the data.\n",
    "\n",
    "\n",
    "Here's an example to illustrate the application of the Unit Vector technique:\n",
    "\n",
    "\n",
    "Let's consider a dataset of two features, height and weight, for a group of individuals. We want to scale the features using unit vector scaling.\n",
    "\n",
    "\n",
    "Original data:\n",
    "Height: [160, 170, 180, 190]\n",
    "Weight: [60, 70, 80, 90]\n",
    "\n",
    "\n",
    "To apply unit vector scaling, we need to calculate the Euclidean norm of each feature vector and then divide each value by its respective norm.\n",
    "\n",
    "\n",
    "First, calculate the Euclidean norm:\n",
    "||[160, 60]|| = sqrt(160^2 + 60^2) = 172.047\n",
    "\n",
    "||[170, 70]|| = sqrt(170^2 + 70^2) = 182.925\n",
    "\n",
    "||[180, 80]|| = sqrt(180^2 + 80^2) = 193.649\n",
    "\n",
    "||[190, 90]|| = sqrt(190^2 + 90^2) = 204.603\n",
    "\n",
    "\n",
    "Next, divide each value by its corresponding norm to obtain the scaled values:\n",
    "\n",
    "Scaled data:\n",
    "Height: [160/172.047, 170/182.925, 180/193.649, 190/204.603]\n",
    "\n",
    "Weight: [60/172.047, 70/182.925, 80/193.649, 90/204.603]\n",
    "\n",
    "Scaled Height: [0.930, 0.930, 0.930, 0.930]\n",
    "\n",
    "Scaled Weight: [0.349, 0.383, 0.416, 0.441]\n",
    "\n",
    "Now, the feature vectors have been scaled using unit vector scaling, resulting in vectors with a magnitude of 1. The direction of the data is preserved, but the \n",
    "magnitude has been standardized.\n",
    "\n",
    "\n",
    "It's important to note that unit vector scaling doesn't necessarily result in values between 0 and 1, as in Min-Max scaling. Instead, it ensures that the magnitude of each feature vector is 1. This technique is particularly useful in scenarios where the length or magnitude of the vectors is relevant, such as in machine learning algorithms like cosine similarity or when dealing with distance-based calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1404812-1622-443f-916a-bea01d8dab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "Height=[160, 170, 180, 190]\n",
    "Weight=[60, 70, 80, 90]\n",
    "df = pd.DataFrame( {'Height': Height, 'Weight': Weight} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a707e7f2-c577-4e4a-b9e2-9a462c8db3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93632918, 0.35112344],\n",
       "       [0.9246781 , 0.38074981],\n",
       "       [0.91381155, 0.40613847],\n",
       "       [0.90373784, 0.42808634]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(df[['Height','Weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3b1eadc-7118-498c-b0ab-e61f15e2e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( normalize(df[['Height','Weight']]), columns = ['Height','Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0240768f-f8c1-4b3e-9300-2025b865853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936329</td>\n",
       "      <td>0.351123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.924678</td>\n",
       "      <td>0.380750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913812</td>\n",
       "      <td>0.406138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.903738</td>\n",
       "      <td>0.428086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height    Weight\n",
       "0  0.936329  0.351123\n",
       "1  0.924678  0.380750\n",
       "2  0.913812  0.406138\n",
       "3  0.903738  0.428086"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7a698-5100-48ad-a7eb-c32f6b70d05d",
   "metadata": {},
   "source": [
    "## Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4b3cf-b56f-4db2-b838-38a332ab537f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc928ad3-0010-4b0f-8072-f75dd2c0e6d9",
   "metadata": {},
   "source": [
    "Min-Max scaling will help bring these features to a common scale, making them comparable and avoiding any bias towards features with larger values.\n",
    "\n",
    "1 Determine the range: Identify the minimum and maximum values for each feature in the dataset,\n",
    "\n",
    "2 Apply Min-Max scaling: Apply the Min-Max scaling formula to each feature in the dataset, which rescales the values to a range between 0 and 1. The formula is as follows:\n",
    "\n",
    "scaled_value = (x - min_value) / (max_value - min_value),\n",
    "\n",
    "3 Perform Min-Max scaling on each feature: Calculate the scaled value for each data point in the dataset using the Min-Max scaling formula. This ensures that the values of each feature are transformed to the range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef5b7785-a3b7-457a-9d32-d91e23b4ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Original dataset\n",
    "data = np.array([\n",
    "    [5, 3, 15],\n",
    "    [10, 4, 30],\n",
    "    [20, 5, 45],\n",
    "    [50, 2, 60]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a066183d-bcfe-4157-83e3-4a9220898a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = data[:, 0]\n",
    "rating = data[:, 1]\n",
    "delivery_time = data[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f07f7de-7802-4a39-9787-1a6d7c8721fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd201b56-49c1-4bf7-873a-d8d3888bfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.reshape(-1, 1)\n",
    "rating = rating.reshape(-1, 1)\n",
    "delivery_time = delivery_time.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c4160cf-9953-4eb0-9e46-ea0fc7e688db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [10],\n",
       "       [20],\n",
       "       [50]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6455c3bd-3331-4516-8574-0bc90b38ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_price = scaler.fit_transform(price)\n",
    "scaled_rating = scaler.fit_transform(rating)\n",
    "scaled_delivery_time = scaler.fit_transform(delivery_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d16807fd-3141-4ed2-84ab-99aca712c5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.11111111],\n",
       "       [0.33333333],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "553e3bdd-a843-4fcc-8dce-d8372fa1bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Price: [0.         0.11111111 0.33333333 1.        ]\n",
      "Scaled Rating: [0.33333333 0.66666667 1.         0.        ]\n",
      "Scaled Delivery Time: [0.         0.33333333 0.66666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Scaled Price:\", scaled_price.flatten())\n",
    "print(\"Scaled Rating:\", scaled_rating.flatten())\n",
    "print(\"Scaled Delivery Time:\", scaled_delivery_time.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64171a97-77d7-4450-92c6-b282aa6f38dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e6317-6e19-4ad9-83ec-cefa97555ac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c566c8-de72-408d-a1fa-ba0ad3ec8959",
   "metadata": {},
   "source": [
    "To perform Min-Max scaling on the given dataset to transform the values to a range of -1 to 1, you can use the following steps:\n",
    "\n",
    "Determine the minimum and maximum values in the dataset. In this case, the minimum is 1, and the maximum is 20.\n",
    "\n",
    "Apply the Min-Max scaling formula to each value in the dataset using the desired range of -1 to 1. The formula is as follows:\n",
    "\n",
    "scaled_value = ((x - min_value) / (max_value - min_value)) * 2 - 1\n",
    "\n",
    "where 'x' represents the original value, 'min_value' is the minimum value of the dataset, and 'max_value' is the maximum value of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1d0d6c6-74e9-46b2-87aa-2db0b5ea18d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled dataset: [-0.9999999999999999, -0.5789473684210525, -0.05263157894736836, 0.47368421052631593, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Original dataset\n",
    "dataset = [1, 5, 10, 15, 20]\n",
    "\n",
    "\n",
    "# Create an instance of MinMaxScaler with the desired feature_range (-1, 1)\n",
    "scaler = MinMaxScaler((-1, 1))\n",
    "\n",
    "# Reshape the dataset to match the expected input shape of MinMaxScaler\n",
    "dataset = [[value] for value in dataset]\n",
    "\n",
    "# Fit the scaler on the original data and transform it\n",
    "scaled_dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "# Flatten the scaled dataset\n",
    "scaled_dataset = [value[0] for value in scaled_dataset]\n",
    "\n",
    "# Print the scaled dataset\n",
    "print(\"Scaled dataset:\", scaled_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2d02b02-991c-4113-92a7-22bc613e2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [value for value in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88e93e71-38f0-4158-a142-1af449bcb3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1]], [[5]], [[10]], [[15]], [[20]]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9862756f-da5e-459d-93f7-e38e270810b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [value[0] for value in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96549767-bd85-4a57-8c3c-f6d2be31f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 10, 15, 20]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47ea2d-0048-4a03-80fc-bb0bd5a4530a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
